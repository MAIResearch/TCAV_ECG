{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0138c0ba",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bb10f0",
   "metadata": {},
   "source": [
    "## Physionet Challenge Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cbb820c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tcav import *\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20479e17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T02:35:33.100254Z",
     "start_time": "2023-11-03T02:35:32.846775Z"
    }
   },
   "outputs": [],
   "source": [
    "physionet_df = pd.read_csv(\"./physionet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d42cb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T02:35:33.138492Z",
     "start_time": "2023-11-03T02:35:33.102690Z"
    }
   },
   "outputs": [],
   "source": [
    "physionet_df.source.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e6a5167",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T02:35:33.161477Z",
     "start_time": "2023-11-03T02:35:33.140903Z"
    }
   },
   "outputs": [],
   "source": [
    "label_list = [\n",
    "    \"atrial fibrillation\",\n",
    "    \"atrial flutter\",\n",
    "    \"bundle branch block\",\n",
    "    \"bradycardia\",\n",
    "    \"complete left bundle branch block, left bundle...\", #\n",
    "    \"complete right bundle branch block, right bund...\",\n",
    "    \"1st degree av block\",\n",
    "    \"incomplete right bundle branch block\",\n",
    "    \"left axis deviation\", \n",
    "    \"left anterior fascicular block\",\n",
    "    \"prolonged pr interval\",\n",
    "    \"low qrs voltages\",\n",
    "    \"prolonged qt interval\",\n",
    "    \"nonspecific intraventricular conduction disorder\",\n",
    "    \"sinus rhythm\", #\n",
    "    \"premature atrial contraction, supraventricular...\",\n",
    "    \"pacing rhythm\",\n",
    "    \"poor R wave Progression\",\n",
    "    \"premature ventricular contractions, ventricula...\",\n",
    "    \"qwave abnormal\", #\n",
    "    \"right axis deviation\",\n",
    "    \"sinus arrhythmia\",\n",
    "    \"sinus bradycardia\",\n",
    "    \"sinus tachycardia\",\n",
    "    \"t wave abnormal\", #\n",
    "    \"t wave inversion\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6022749",
   "metadata": {},
   "source": [
    "## add sublabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b1715e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T02:35:33.184546Z",
     "start_time": "2023-11-03T02:35:33.163518Z"
    }
   },
   "outputs": [],
   "source": [
    "physionet_df['26'] = physionet_df['0'] | physionet_df['1']\n",
    "label_list.append(\"atrial fibrillation+atrial flutter\")\n",
    "\n",
    "physionet_df['27'] = physionet_df['24'] | physionet_df['25']\n",
    "label_list.append(\"t wave abnormal + t wave inversion \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff89efb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T02:35:33.205408Z",
     "start_time": "2023-11-03T02:35:33.186549Z"
    }
   },
   "outputs": [],
   "source": [
    "label_list = np.array(label_list)\n",
    "for idx,label_name in enumerate(label_list):\n",
    "    print(idx, label_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92056399",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T02:35:33.676588Z",
     "start_time": "2023-11-03T02:35:33.314723Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "hist_label_list = np.array(label_list[:])\n",
    "label_dist = np.array(physionet_df[[str(i) for i in range(len(hist_label_list))]].sum().tolist())\n",
    "order_idx_list = np.argsort(label_dist)\n",
    "\n",
    "# Assume you have these two lists\n",
    "labels = hist_label_list[order_idx_list]\n",
    "counts = label_dist[order_idx_list]\n",
    "\n",
    "plt.figure(figsize=(10, 6))  # Optional: You can adjust the size of the figure\n",
    "\n",
    "plt.bar(range(len(labels)), counts, color='skyblue', edgecolor='black')\n",
    "\n",
    "plt.xticks(range(len(labels)), labels, rotation=270)\n",
    "\n",
    "plt.title('Physionet label distribution')  # Title of the plot\n",
    "plt.xlabel('Labels')  # X-axis label\n",
    "plt.ylabel('Counts')  # Y-axis label\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde42aea",
   "metadata": {},
   "source": [
    "## Make Target and Random Concept Dataset\n",
    "- Prioritize extracting data with a single clear label from the multilabel data\n",
    "- Ensure the distribution of source_id is as uniform as possible within each label\n",
    "- For random control, randomly extract data from the remaining data to match the source_id distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3cd7ed2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T02:35:33.702031Z",
     "start_time": "2023-11-03T02:35:33.678962Z"
    }
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b64b58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T02:35:35.291468Z",
     "start_time": "2023-11-03T02:35:33.704332Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_idx_list = sorted([4,26,5,8,20,12,13,19,27,21,22,23])#\n",
    "\n",
    "random_concept_n:int = 10 # how many random concept to make\n",
    "sample_n = 200 # how many sample to make\n",
    "random_seed = 777 # random seed\n",
    "\n",
    "concept_file_dict = dict()\n",
    "\n",
    "total_file_set= set(physionet_df.filename.tolist()) #\n",
    "control_file_set = set(physionet_df.filename.tolist()) #random control file pool: \n",
    "\n",
    "for idx in np.argsort(label_dist[selected_idx_list]): # least label first\n",
    "    select_idx = selected_idx_list[idx]\n",
    "    name = label_list[select_idx]\n",
    "    print(name)\n",
    "    \n",
    "    target_df = physionet_df[physionet_df[str(select_idx)]==1].copy()\n",
    "    target_df['count'] = target_df[[str(i) for i in range(len(label_list))]].sum(axis=1).tolist()\n",
    "        \n",
    "    exist_file_df = pd.DataFrame(total_file_set,columns=['filename'])\n",
    "    target_df = pd.merge(target_df,exist_file_df,on='filename',how='inner')\n",
    "\n",
    "    random.seed(random_seed)\n",
    "    random_number = list(range(len(target_df)))\n",
    "    shuffle(random_number)\n",
    "    target_df['random_seed'] = random_number\n",
    "    \n",
    "    source_list = target_df.source.value_counts(ascending=True).index.tolist()\n",
    "    source_sample_list = list()\n",
    "    \n",
    "    remain_n = sample_n\n",
    "    each_n = int(sample_n/len(source_list))\n",
    "    \n",
    "    for i,source in enumerate(source_list):\n",
    "        \n",
    "        source_sample_df = target_df[target_df.source==source]\n",
    "        if i==len(source_list)-1:\n",
    "            target_sample_df = source_sample_df.sort_values(['count','random_seed']).head(remain_n)\n",
    "        else:\n",
    "            target_sample_df = source_sample_df.sort_values(['count','random_seed']).head(each_n)\n",
    "            remain_n -=len(target_sample_df)\n",
    "        print(name,source,target_sample_df.shape)\n",
    "        source_sample_list.append(target_sample_df)\n",
    "    \n",
    "    target_sample_df = pd.concat(source_sample_list)\n",
    "    file_list= target_sample_df.filename.tolist()\n",
    "    concept_file_dict[name] = target_sample_df\n",
    "    \n",
    "    total_file_set = total_file_set-set(file_list)\n",
    "    control_file_set = control_file_set-set(target_df.filename.tolist())\n",
    "    \n",
    "    \n",
    "    if len(file_list)<sample_n:\n",
    "        print(f\"[Caution]{name} label is insufficient, file_n: {len(file_list)}\")\n",
    "    else:\n",
    "        print(f\"[Success]{name} label is prepared, sample_n: {len(file_list)}\")\n",
    "\n",
    "remain_n = sample_n\n",
    "for random_idx in range(random_concept_n):\n",
    "    random_sample_df = pd.DataFrame(list(control_file_set),columns=['filename'])\n",
    "    random_sample_df = pd.merge(random_sample_df,physionet_df,on='filename',how='inner')\n",
    "    \n",
    "    each_n = int(sample_n/len(random_sample_df.source.unique()))\n",
    "    \n",
    "    random_sample_df = random_sample_df.groupby('source').sample(each_n,random_state=random_seed)\n",
    "    \n",
    "    concept_file_dict[f\"random_concept_{random_idx}\"] = random_sample_df\n",
    "        \n",
    "    print(f\"[Success] random{random_idx} label is prepared, sample_n: {len(file_list)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d33e337",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T02:35:35.392692Z",
     "start_time": "2023-11-03T02:35:35.295679Z"
    }
   },
   "outputs": [],
   "source": [
    "#check random label list\n",
    "random_sample_df = pd.DataFrame(list(control_file_set),columns=['filename'])\n",
    "random_sample_df = pd.merge(random_sample_df,physionet_df,on='filename',how='inner')\n",
    "print(random_sample_df.shape)\n",
    "for col in selected_idx_list:\n",
    "    print(random_sample_df[str(col)].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3f005e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T02:35:35.423869Z",
     "start_time": "2023-11-03T02:35:35.394889Z"
    }
   },
   "outputs": [],
   "source": [
    "#check random label list\n",
    "random_label_list = label_list[random_sample_df[[str(i) for i in range(0,28)]].sum(axis=0)!=0]\n",
    "random_label_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effe5de4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T02:51:05.826172Z",
     "start_time": "2023-06-28T02:51:05.809796Z"
    }
   },
   "source": [
    "## check concept dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa649175",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T02:35:38.777903Z",
     "start_time": "2023-11-03T02:35:35.426163Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count_df_list = list()\n",
    "for name, target_df in concept_file_dict.items():\n",
    "    count_df = pd.DataFrame(target_df.source.value_counts()).T.rename({'source':name})\n",
    "    count_df_list.append(count_df)\n",
    "    target_df.source.hist(label=name)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8924b1f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T02:35:38.820576Z",
     "start_time": "2023-11-03T02:35:38.780304Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cda7b9fc",
   "metadata": {},
   "source": [
    "# Setting for TCAV analysis\n",
    "- target classifier and target_label dataframe are required\n",
    "- USER must define following code for their research setting\n",
    "- USER CUSTUM CODE: get_ecg_tensor, TCAV_dataset,model_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6c8fc9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T02:35:38.847265Z",
     "start_time": "2023-11-03T02:35:38.822679Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "[Example]\n",
    "ecg_tensor = get_ecg_tensor(filename)\n",
    "classifier = get_model(model_path)\n",
    "classifier(ecg_tensor)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_ecg_tensor(filename,)->torch.Tensor:\n",
    "    \"\"\"USER CUSTUM FUNCTION\n",
    "    USER have to define this function\n",
    "    input: filename, etc...\n",
    "    output: ecg_tensor for model input\n",
    "    \"\"\"\n",
    "    \n",
    "    return ecg_tensor\n",
    "\n",
    "class TCAV_dataset(torch.utils.data.Dataset):\n",
    "    \"\"\"USER CUSTUM CLASS\n",
    "    USER have to define this class\n",
    "    input: file_df, device, etc...\n",
    "    \"\"\"\n",
    "    def __init__(self,file_df, device):\n",
    "        self.file_df = file_df.reset_index(drop=True)\n",
    "        self.device = device\n",
    "    \n",
    "    def __getitem__(self,index)->torch.Tensor:\n",
    "        filename = self.file_df.loc[index].filename\n",
    "        output = get_ecg_tensor(filename)\n",
    "        return output.to(self.device)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_df)\n",
    "    \n",
    "    \n",
    "def get_model(model_path)->torch.nn.Module:\n",
    "    \"\"\"\n",
    "    USER CUSTUM FUNCTION\n",
    "    USER have to define this function\n",
    "    input: model_path, etc...\n",
    "    output: model for TCAV analaysis\n",
    "    \"\"\"\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50aeec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:3\"\n",
    "label_df_path = \"LVSD_label.csv\" # this is label file for target concept\n",
    "label_df = pd.read_csv(label_df_path)\n",
    "\n",
    "label_df_target = label_df[label_df['1']>0.5].sample(1000,random_state=random_seed)\n",
    "target_tensor_list = list()\n",
    "\n",
    "for oid in label_df_target.filename:\n",
    "    try:\n",
    "        out = get_ecg_tensor(oid)\n",
    "        target_tensor_list.append(out)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "target_tensor = torch.stack(target_tensor_list).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905ca91c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T02:35:59.029325Z",
     "start_time": "2023-11-03T02:35:58.967331Z"
    }
   },
   "outputs": [],
   "source": [
    "model_path = \"checkpoint.pth\" #this is model path for TCAV analysis\n",
    "classifier = get_model(model_path)\n",
    "\n",
    "classifier.eval()\n",
    "classifier.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68859848",
   "metadata": {},
   "source": [
    "# TCAV with captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9fdc30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T02:35:59.055859Z",
     "start_time": "2023-11-03T02:35:59.031629Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from captum.attr import LayerIntegratedGradients\n",
    "\n",
    "from captum.concept import TCAV\n",
    "from captum.concept import Concept\n",
    "\n",
    "from captum.concept._utils.data_iterator import dataset_to_dataloader\n",
    "from captum.concept._utils.common import concepts_to_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9c1714",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T02:35:59.094326Z",
     "start_time": "2023-11-03T02:35:59.060260Z"
    }
   },
   "outputs": [],
   "source": [
    "tcav_concept_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf2e449",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T02:35:59.127088Z",
     "start_time": "2023-11-03T02:35:59.096645Z"
    }
   },
   "outputs": [],
   "source": [
    "for idx, (name,concept_df) in enumerate(concept_file_dict.items()):\n",
    "    tcav_dataset = TCAV_dataset(concept_df,device)\n",
    "    concept_iter = dataset_to_dataloader(tcav_dataset)\n",
    "    tcav_concept = Concept(idx,name,concept_iter)\n",
    "    tcav_concept_dict[name] = tcav_concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90749329",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T02:35:59.238494Z",
     "start_time": "2023-11-03T02:35:59.217435Z"
    }
   },
   "outputs": [],
   "source": [
    "layers = [\"blk1d.0.2.conv2\",\"blk1d.1.2.conv2\",\"blk1d.2.2.conv2\",\"blk1d.3.2.conv2\"] # this is layer name in model for TCAV analysis\n",
    "tcav_concept_dict.keys()\n",
    "mytcav = TCAV(model=classifier,layers=layers,\n",
    "              layer_attr_method =LayerIntegratedGradients(classifier, None, multiply_by_inputs=False) ) #\n",
    "print(tcav_concept_dict.keys())\n",
    "list(tcav_concept_dict.values())\n",
    "experimental_set_rand = [list(tcav_concept_dict.values())]\n",
    "tcav_scores_w_random = mytcav.interpret(inputs=target_tensor,\n",
    "                                        experimental_sets=experimental_set_rand,\n",
    "                                        target=1,\n",
    "                                        n_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c99afd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T02:41:57.719108Z",
     "start_time": "2023-11-03T02:41:57.719081Z"
    }
   },
   "outputs": [],
   "source": [
    "from tcav import plot_tcav_scores\n",
    "plot_tcav_scores(experimental_set_rand,tcav_scores_w_random,layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6186cc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T04:49:05.567427Z",
     "start_time": "2023-08-04T04:49:05.557212Z"
    }
   },
   "source": [
    "## statistical signification test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a014d238",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T02:41:57.727112Z",
     "start_time": "2023-11-03T02:41:57.727092Z"
    }
   },
   "outputs": [],
   "source": [
    "tcav_concept_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230e52f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T02:41:57.728963Z",
     "start_time": "2023-11-03T02:41:57.728942Z"
    }
   },
   "outputs": [],
   "source": [
    "exp_sets_for_each = list()\n",
    "\n",
    "for concept_name in tcav_concept_dict.keys():\n",
    "    \n",
    "    if \"random_concept\" in concept_name:\n",
    "        continue\n",
    "    \n",
    "    experimental_sets = list()\n",
    "    target_concept = tcav_concept_dict[concept_name]\n",
    "    random_concepts = [tcav_concept_dict[f\"random_concept_{i}\"] for i in range(0, random_concept_n)]\n",
    "\n",
    "\n",
    "    experimental_sets.extend([[target_concept, random_concept] for random_concept in random_concepts])\n",
    "    \n",
    "    exp_sets_for_each.append(experimental_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cf4540",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T02:41:57.730724Z",
     "start_time": "2023-11-03T02:41:57.730706Z"
    }
   },
   "outputs": [],
   "source": [
    "block_tcav_result_list = list()\n",
    "block_tcav_random_score_list = list()\n",
    "score_type = \"sign_count\" #'magnitude'\n",
    "for block_n in [0,1,2,3]:\n",
    "    target_layer = f'blk1d.{block_n}.2.conv2' #your layer name in model\n",
    "    \n",
    "    p_val_out_list = list()\n",
    "    random_score_each_block=list()\n",
    "    for target_exp_set in exp_sets_for_each:\n",
    "        out = get_confidnece_plot(mytcav,target_exp_set,target_layer,score_type,target_tensor,device,label_name=target_exp_set[0][0].name)\n",
    "        p_val_out_list.append(out)\n",
    "        random_score_each_block.append(out[-1])\n",
    "\n",
    "\n",
    "    name_list = [target_exp_set[0][0].name for target_exp_set in exp_sets_for_each]\n",
    "    mean_list = [out[1][0] for out in p_val_out_list]\n",
    "    h_list = [out[1][1] for out in p_val_out_list]\n",
    "    block_tcav_result_list.append([mean_list,h_list])\n",
    "    block_tcav_random_score_list.append(random_score_each_block)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162a8cb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T02:41:57.732280Z",
     "start_time": "2023-11-03T02:41:57.732262Z"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "block_tcav_radom_result_list = [mean_confidence_interval(list(chain(*block_tcav_random_score_list[i]))) for i in  [0,1,2,3]]\n",
    "print(block_tcav_radom_result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c10ead9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T08:57:10.679152Z",
     "start_time": "2024-01-22T08:57:10.614084Z"
    }
   },
   "outputs": [],
   "source": [
    "reindex_list = [6,0,1,5,7,4,8,3,2,-1]\n",
    "\n",
    "block_tav_score_list =np.array([\n",
    "    block_tcav_result_list[0][0]+[block_tcav_radom_result_list[0][0]],\n",
    "    block_tcav_result_list[1][0]+[block_tcav_radom_result_list[1][0]],\n",
    "    block_tcav_result_list[2][0]+[block_tcav_radom_result_list[2][0]],\n",
    "    block_tcav_result_list[3][0]+[block_tcav_radom_result_list[3][0]]])\n",
    "\n",
    "block_tav_score_list=block_tav_score_list[:,reindex_list]\n",
    "\n",
    "\n",
    "block_tav_ci_list =np.array([\n",
    "    block_tcav_result_list[0][1]+[block_tcav_radom_result_list[0][1]],\n",
    "    block_tcav_result_list[1][1]+[block_tcav_radom_result_list[1][1]],\n",
    "    block_tcav_result_list[2][1]+[block_tcav_radom_result_list[2][1]],\n",
    "    block_tcav_result_list[3][1]+[block_tcav_radom_result_list[3][1]]])\n",
    "block_tav_ci_list = block_tav_ci_list[:,reindex_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba6a932",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T08:57:05.256173Z",
     "start_time": "2024-01-22T08:57:05.197208Z"
    }
   },
   "outputs": [],
   "source": [
    "from tcav import draw_heatmap\n",
    "matrix = block_tav_score_list\n",
    "rows = [\"Block1\", \"Block2\", \"Block3\",\"Block4\"]\n",
    "cols = list(np.array(list(tcav_concept_dict)[:])[reindex_list])\n",
    "fig = draw_heatmap(matrix,block_tav_ci_list, row_names=rows, col_names=cols, cell_width=2, cell_height=1, vmin=0.1, vmax=1,cmap='Reds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec94476c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-18T08:20:10.341841Z",
     "start_time": "2023-10-18T08:20:09.770393Z"
    }
   },
   "outputs": [],
   "source": [
    "fig.savefig('TCAV_block_figure.png',dpi=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cb1eff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "solver2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "261.818px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
